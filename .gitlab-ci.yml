image: docker:latest
services:
  - name : docker:dind  # Docker-in-Docker pour pouvoir utiliser Docker dans le pipeline
    alias: docker

stages:
- Linter
- Build image - Compilation
- Security scan
- Test acceptation
- Unit testing
- Integration testing
- Sonar - Quality
- Release image - Packaging


lint_code:
  stage: Linter
  image: python:3.9-slim
  before_script:
    - apt-get update && apt-get install -y wget  # Installe wget
    - pip install --upgrade pip
    - pip install flake8
  script:
    # Lint Python en ignorant :
    #   - E501 : lignes trop longues
    #   - E303 : trop de lignes vides
    # Ne fait pas échouer le job même s’il y a des erreurs
    - flake8 --ignore=E501,E303 webapp/ || true

    # Télécharger hadolint (outil de lint Dockerfile)
    - wget -O /bin/hadolint https://github.com/hadolint/hadolint/releases/latest/download/hadolint-Linux-x86_64
    - chmod +x /bin/hadolint

    # Analyse Dockerfile avec hadolint
    # Ne fait pas échouer le job même s’il y a des alertes
    - hadolint Dockerfile || true
  # rules:
  #   - changes:
  #       - Dockerfile
  #       - webapp/**/*.py
  #       - scripts/**/*.py       # ou tout autre fichier source impactant ton build
  #       - path/to/other/files/**  # ajoute ici les dossiers/fichiers nécessaires 
  #   - when: never


  allow_failure: false  # Ce job doit réussir, même s’il affiche des erreurs


build:
  #image: docker:latest
  stage: Build image - Compilation
  # services:
  #   - docker:dind  # Docker-in-Docker pour pouvoir utiliser Docker dans le pipeline
  script:
    - docker build -t alpinehelloworld .  # Construction de l'image avec le tag "alpinehelloworld"
    - docker save alpinehelloworld > alpinehelloworld.tar
  artifacts:
    paths: 
      - alpinehelloworld.tar
  # rules:
  # - changes:
  #     - Dockerfile
  #     - webapp/**/*.py
  #     - scripts/**/*.py       # ou tout autre fichier source impactant ton build
  #     - path/to/other/files/**  # ajoute ici les dossiers/fichiers nécessaires 
  # - when: never


#Job pour analyser les vulnérabilités de sécurité avec Trivy
scan_security:
  stage: Security scan
  image: 
    name: aquasec/trivy:0.29.0
    entrypoint: [""]
  script:
    # Utilisation de la commande docker run pour scanner l'image alpinehelloworld
    #- docker run --rm aquasec/trivy image alpinehelloworld --exit-code 1 --no-progress  # Lance le scan sur l'image "alpinehelloworld"
   - trivy image --severity HIGH,CRITICAL --exit-code 0 --input alpinehelloworld.tar --format table --output trivy-report.json #.html, .txt, .json en fonction des types de dcos souhaités :)
  allow_failure: false  # Fait échouer le pipeline si des vulnérabilités sont trouvées
  artifacts:
    paths:
      - trivy-report.json
  
  # rules:
  # - changes:
  #     - Dockerfile
  #     - webapp/**/*.py
  #     - scripts/**/*.py       # ou tout autre fichier source impactant ton build
  #     - path/to/other/files/**  # ajoute ici les dossiers/fichiers nécessaires 
  # - when: never

  
    # Job de tests unitaires
test_unitaires: 
  stage: Unit testing  
  image: python:3.9-slim  # Utilisation de l'image Docker Python 3.9 allégée
  before_script:
    - pip install --upgrade pip  # Met à jour pip pour garantir qu'il fonctionne avec les dernières versions des paquets
    - pip install -r webapp/requirements.txt  # Installe les dépendances du projet à partir du fichier requirements.txt dans le répertoire 'webapp'
    - pip install pytest  # Installe Pytest pour exécuter les tests unitaires
  script:
    - mkdir -p webapp/tests/results  # Crée le répertoire pour les résultats des tests (si nécessaire)
    - coverage run --source=webapp -m pytest webapp/tests.py  # Exécute les tests avec 'pytest' tout en mesurant la couverture de code uniquement sur le dossier 'webapp'
    - coverage xml -o webapp/tests/results/coverage.xml       # Génère un rapport de couverture au format XML, nécessaire pour SonarCloud ou d'autres outils d'analyse
    - pytest webapp/tests.py --junitxml=webapp/tests/results/report.xml  # Exécute les tests dans le fichier 'tests.py' et génère un rapport XML
  artifacts:
    paths:
      - webapp/tests/results  # Sauvegarde le répertoire contenant les résultats des tests pour qu'il soit accessible dans GitLab CI
    when: always  # Sauvegarde les résultats même si le job échoue, ce qui peut être utile pour déboguer

  allow_failure: false  # Si les tests échouent, le pipeline échoue
  # rules:
  #   - changes:
  #       - Dockerfile
  #       - webapp/**/*.py
  #       - scripts/**/*.py       # ou tout autre fichier source impactant ton build
  #       - path/to/other/files/**  # ajoute ici les dossiers/fichiers nécessaires 
  #   - when: never

test_integration:
  stage: Integration testing
  image: python:3.9-slim
  before_script:
    - pip install --upgrade pip
    - pip install --root-user-action=ignore -r webapp/requirements.txt
    - pip install pytest
    - export PYTHONPATH=$PYTHONPATH:$(pwd)
    # Démarrer le serveur ou base de test si nécessaire
  script:
    - mkdir -p webapp/tests/results
    - pytest webapp/tests/integration/ --junitxml=webapp/tests/results/integration_report.xml
  artifacts:
    paths:
      - webapp/tests/results
    when: always
  allow_failure: false
  # rules:
  #   - changes:
  #       - Dockerfile
  #       - webapp/**/*.py
  #       - scripts/**/*.py       # ou tout autre fichier source impactant ton build
  #       - path/to/other/files/**  # ajoute ici les dossiers/fichiers nécessaires 
  #   - when: never

sonarcloud_scan:
  stage: Sonar - Quality
  image: sonarsource/sonar-scanner-cli:latest
  script:
    # Lancer l’analyse SonarCloud avec les paramètres du projet
    - sonar-scanner -Dsonar.projectKey=cheikhfallkhouma_alpinehelloworld-project -Dsonar.organization=alpinehelloworld-project -Dsonar.sources=. -Dsonar.host.url=https://sonarcloud.io -Dsonar.python.coverage.reportPaths=webapp/tests/results/coverage.xml -Dsonar.login=${SONAR_TOKEN}
  cache:
        key: "${CI_JOB_NAME}"
        paths:
          - .sonar/cache

  # only:
  #   - merge_requests
  #   - main

release image:
  stage: Release image - Packaging
  script:
    # Charger l'image Docker à partir du fichier tar
    - docker load < alpinehelloworld.tar
    # Taguer l'image Docker avec le nom de l'image et la révision du commit
    - docker tag alpinehelloworld "${IMAGE_NAME}:${CI_COMMIT_REF_NAME}"
    # Taguer l'image Docker avec le nom de l'image et le short SHA du commit
    - docker tag alpinehelloworld "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
    # Se connecter au registre Docker avec les identifiants spécifiés dans les variables d'environnement
    - docker login -u "$CI_REGISTRY_USER" -p "$CI_REGISTRY_PASSWORD" $CI_REGISTRY
    # Pousser l'image Docker avec le tag basé sur le nom de la branche (révision du commit)
    - docker push "${IMAGE_NAME}:${CI_COMMIT_REF_NAME}"
    # Pousser l'image Docker avec le tag basé sur le short SHA du commit
    - docker push "${IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}"
  # rules:
  #     - changes:
  #         - Dockerfile
  #         - webapp/**/*.py
  #         - scripts/**/*.py       # ou tout autre fichier source impactant ton build
  #         - path/to/other/files/**  # ajoute ici les dossiers/fichiers nécessaires 
  #     - when: never


